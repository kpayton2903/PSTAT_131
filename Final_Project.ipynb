{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Salaries for MLB Players\n",
    "### Kevin Payton\n",
    "### PSTAT 131 Fall 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## MLB Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Loading our Data and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.read_csv('Master.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exploring, Merging, and Tidying our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I will import all my libraries:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will first import my data I have decided on so far. Everything comes from Kaggle at the following link: https://www.kaggle.com/datasets/open-source-sports/baseball-databank?resource=download. So far I have decided on using the Master.csv, Salaries.csv, and Batting.csv files which all have data from 1871 through 2015, but I will only be working with data from year 2000 to 2015. The Master.csv file contains personal information of all the players in the dataset, but I will only be using this to gather the names of players to make importing any future data easier since currently my datasets rely on player IDs. The Salaries.csv file contains team and league information, as well as the salary players have for any given year. Finally, my Batting.csv file contains various batting statistics for players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13312, 5)\n",
      "(13304, 6)\n",
      "(13312, 6)\n"
     ]
    }
   ],
   "source": [
    "master['nameFull'] = master['nameFirst'] + ' ' + master['nameLast']\n",
    "names = master[['playerID', 'nameFull']]\n",
    "\n",
    "salaries = pd.read_csv('Salaries.csv')\n",
    "salaries_post_2000 = salaries[salaries['yearID'] >= 2000]\n",
    "print(salaries_post_2000.shape)\n",
    "\n",
    "merged_data = pd.merge(salaries_post_2000, names, on='playerID', how='inner')\n",
    "print(merged_data.shape)\n",
    "\n",
    "merged_data_left = pd.merge(salaries_post_2000, names, on='playerID', how='left')\n",
    "print(merged_data_left.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing my Master.csv file, I first decided to make a full name column because the player's first and last names were separated. I then removed all columns except the playerID and nameFull to make the merging with salaries easier since all the other columns were unneeded. As you can see from the output above we are then left with 18846 rows and 2 columns, with the rows each representing players. We are left with so many because we currently still have values from every player that has played since 1871 through 2015, but all those prior to 2000 will be removed once we merge with our salaries dataset. \n",
    "\n",
    "I then imported my Salaries.csv file and filtered out all player data prior to 2000 to simplify things, leaving us with 13312 rows and 5 columns containing simple data about a player, the team they started the season and its league, as well as the year and their salary. This file does not contain information on if a player was traded during the year, because their salary stays the same. This is an issue I might have later when dealing with the batting information, because there might be multiple rows for the same player during a given year.\n",
    "\n",
    "I was then able to finally merge the two datasets together, and I did so with both a left and an inner join so I could see if we were missing any information on any player's names. As you can see above, we were missing 8 player's names from the names data frame so I will create a function to discover the index of these players, as well as their playerID so I can try and find some more information about them in our Master.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['harriwi10', 'castiru02', 'rosajo01', 'arrueba01', 'furcara02', 'castiru02', 'rosajo01', 'harriwi10']\n"
     ]
    }
   ],
   "source": [
    "null_data = merged_data_left['nameFull'].isnull()\n",
    "missing_names = []\n",
    "\n",
    "for ind in merged_data_left.index:\n",
    "    if null_data.loc[ind] == True:\n",
    "        missing_names.append(merged_data_left.loc[ind, 'playerID'])\n",
    "    \n",
    "print(missing_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [playerID, birthYear, birthMonth, birthDay, birthCountry, birthState, birthCity, deathYear, deathMonth, deathDay, deathCountry, deathState, deathCity, nameFirst, nameLast, nameGiven, weight, height, bats, throws, debut, finalGame, retroID, bbrefID, nameFull]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 25 columns]\n",
      "Empty DataFrame\n",
      "Columns: [playerID, birthYear, birthMonth, birthDay, birthCountry, birthState, birthCity, deathYear, deathMonth, deathDay, deathCountry, deathState, deathCity, nameFirst, nameLast, nameGiven, weight, height, bats, throws, debut, finalGame, retroID, bbrefID, nameFull]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 25 columns]\n",
      "Empty DataFrame\n",
      "Columns: [playerID, birthYear, birthMonth, birthDay, birthCountry, birthState, birthCity, deathYear, deathMonth, deathDay, deathCountry, deathState, deathCity, nameFirst, nameLast, nameGiven, weight, height, bats, throws, debut, finalGame, retroID, bbrefID, nameFull]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 25 columns]\n",
      "Empty DataFrame\n",
      "Columns: [playerID, birthYear, birthMonth, birthDay, birthCountry, birthState, birthCity, deathYear, deathMonth, deathDay, deathCountry, deathState, deathCity, nameFirst, nameLast, nameGiven, weight, height, bats, throws, debut, finalGame, retroID, bbrefID, nameFull]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 25 columns]\n",
      "Empty DataFrame\n",
      "Columns: [playerID, birthYear, birthMonth, birthDay, birthCountry, birthState, birthCity, deathYear, deathMonth, deathDay, deathCountry, deathState, deathCity, nameFirst, nameLast, nameGiven, weight, height, bats, throws, debut, finalGame, retroID, bbrefID, nameFull]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 25 columns]\n",
      "Empty DataFrame\n",
      "Columns: [playerID, birthYear, birthMonth, birthDay, birthCountry, birthState, birthCity, deathYear, deathMonth, deathDay, deathCountry, deathState, deathCity, nameFirst, nameLast, nameGiven, weight, height, bats, throws, debut, finalGame, retroID, bbrefID, nameFull]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 25 columns]\n",
      "Empty DataFrame\n",
      "Columns: [playerID, birthYear, birthMonth, birthDay, birthCountry, birthState, birthCity, deathYear, deathMonth, deathDay, deathCountry, deathState, deathCity, nameFirst, nameLast, nameGiven, weight, height, bats, throws, debut, finalGame, retroID, bbrefID, nameFull]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 25 columns]\n",
      "Empty DataFrame\n",
      "Columns: [playerID, birthYear, birthMonth, birthDay, birthCountry, birthState, birthCity, deathYear, deathMonth, deathDay, deathCountry, deathState, deathCity, nameFirst, nameLast, nameGiven, weight, height, bats, throws, debut, finalGame, retroID, bbrefID, nameFull]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "for playerid in missing_names:\n",
    "    print(master.loc[master['playerID'] == playerid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, I was unable to find these names simply from going through my full Master.csv file, so I will have to do some extra research in case the ID was simply input wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was first able to discover that the player with the ID 'harriwi10' was Will Harris and was given the ID 'harriwi02' in both Master.csv and Batting.csv. The player with the ID 'castiru02' was Rusney Castillo with the ID 'castiru01'. The player with the ID 'rosajo01' was Jorge De La Rosa and also had data under the ID 'delarjo01'. The player with the ID 'arrueba01' was Erisbel Arruebarrena who also had data under the ID 'arrueer01'. Finally, the player with the ID 'furcara02' was Rafael Furcal who also had data under 'furcara01'. Before I do any work with my data, I will go through and fix these inconsistencies, but for now I have outlined what needs to be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          yearID     teamID       lgID   playerID     salary\n",
      "23965  harriwi02  harriwi02  harriwi02  harriwi02  harriwi02\n",
      "25044  harriwi02  harriwi02  harriwi02  harriwi02  harriwi02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kpayt\\AppData\\Local\\Temp\\ipykernel_34320\\2041775303.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  salaries_post_2000[salaries_post_2000['playerID'] == 'harriwi10'] = 'harriwi02'\n",
      "C:\\Users\\kpayt\\AppData\\Local\\Temp\\ipykernel_34320\\2041775303.py:1: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'harriwi02' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  salaries_post_2000[salaries_post_2000['playerID'] == 'harriwi10'] = 'harriwi02'\n",
      "C:\\Users\\kpayt\\AppData\\Local\\Temp\\ipykernel_34320\\2041775303.py:1: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'harriwi02' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  salaries_post_2000[salaries_post_2000['playerID'] == 'harriwi10'] = 'harriwi02'\n"
     ]
    }
   ],
   "source": [
    "salaries_post_2000.loc[''] = 'harriwi02'\n",
    "print(salaries_post_2000[salaries_post_2000['playerID'] == 'harriwi02'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22084, 22)\n",
      "playerID    0\n",
      "nameFull    0\n",
      "yearID      0\n",
      "salary      0\n",
      "teamID_x    0\n",
      "stint       0\n",
      "lgID_x      0\n",
      "G           0\n",
      "AB          0\n",
      "R           0\n",
      "H           0\n",
      "2B          0\n",
      "3B          0\n",
      "HR          0\n",
      "RBI         0\n",
      "SB          0\n",
      "CS          0\n",
      "BB          0\n",
      "SO          0\n",
      "IBB         0\n",
      "HBP         0\n",
      "SH          0\n",
      "SF          0\n",
      "GIDP        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "batting_stats = pd.read_csv('Batting.csv')\n",
    "batting_stats = batting_stats[batting_stats['yearID'] >= 2000]\n",
    "print(batting_stats.shape)\n",
    "\n",
    "new_merged = pd.merge(batting_stats, merged_data, on=['playerID', 'yearID'], how='inner')\n",
    "\n",
    "final_data = new_merged[['playerID', 'nameFull', 'yearID', 'salary', 'teamID_x', 'stint',\n",
    "                        'lgID_x', 'G', 'AB', 'R', 'H', '2B', '3B', 'HR', 'RBI', 'SB', 'CS',\n",
    "                        'BB', 'SO', 'IBB', 'HBP', 'SH', 'SF', 'GIDP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
